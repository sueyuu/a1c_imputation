{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP2YEBTWusAXBGgOoejxgM1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A7W8eFxw0G1S","executionInfo":{"status":"ok","timestamp":1747271180997,"user_tz":-480,"elapsed":14335,"user":{"displayName":"Shem Lawalata","userId":"13541090692546704517"}},"outputId":"e91dc0cc-e020-4c9c-e324-3d99bb5e8897"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["#demographic, grouping and append hba1c\n","import pandas as pd\n","import zipfile\n","from google.colab import drive\n","\n","#drive.mount('/content/drive')\n","\n","# Configuration\n","base_path = '/content/drive/MyDrive/Digital Health/T1_data_time_trial'\n","demographic_path = f'{base_path}/wadwa2023_demographic.csv'\n","hba1c_path = f'{base_path}/Wadwa_hba1c.csv'\n","trial_zip_path = f'{base_path}/wadwa2023.zip'\n","output_path = f'{base_path}/Wadwa2023_demographic_with_groups.csv'\n","\n","# Load data\n","demo_df = pd.read_csv(demographic_path)\n","hba1c_df = pd.read_csv(hba1c_path)\n","\n","# Merge HbA1c data\n","merged_df = pd.merge(demo_df, hba1c_df[['PtID', 'hba1c']], on='PtID', how='left')\n","\n","# Add Age Group\n","def get_age_group(age):\n","    if pd.isna(age): return 'Unknown'\n","    try:\n","        age = float(age)\n","        if age < 10: return '<10'\n","        if age < 20: return '<20'\n","        if age <= 65: return '20-65'\n","        return '≥65'\n","    except:\n","        return 'Unknown'\n","\n","merged_df['Age_group'] = merged_df['AgeAsofEnrollDt'].apply(get_age_group)\n","\n","# Enhanced trial participation check\n","def has_trial_data(ptid):\n","    \"\"\"Check for CGM files with both:\n","    1. Original PtID format (1_)\n","    2. 2xxx format (2001_)\"\"\"\n","    try:\n","        with zipfile.ZipFile(trial_zip_path) as z:\n","            # Try both possible formats\n","            patterns = [\n","                f\"{ptid}_\",       # Original format (1_)\n","                f\"2{int(ptid):03d}_\"  # 2xxx format (2001_)\n","            ]\n","\n","            # Check all files in zip\n","            for f in z.namelist():\n","                if any(f.startswith(p) for p in patterns) and \\\n","                   f.endswith('.npy') and \\\n","                   not f.endswith('_time.npy'):\n","                    return True\n","            return False\n","    except Exception as e:\n","        print(f\"Error checking trial data for PtID {ptid}: {str(e)}\")\n","        return False\n","\n","merged_df['In_trial'] = merged_df['PtID'].apply(\n","    lambda x: '1' if has_trial_data(x) else '0'\n",")\n","\n","# Verify matches\n","print(\"Sample PtID mappings:\")\n","sample_ptids = merged_df['PtID'].head(5)\n","for ptid in sample_ptids:\n","    print(f\"Demographic PtID: {ptid} → CGM patterns: [{ptid}_, 2{int(ptid):03d}_]\")\n","\n","# Save results\n","merged_df.to_csv(output_path, index=False)\n","print(f\"\\nEnhanced demographic data saved to {output_path}\")\n","print(\"\\nTrial participation summary:\")\n","print(merged_df['In_trial'].value_counts())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vV3Q98-F0QKL","executionInfo":{"status":"ok","timestamp":1746851024950,"user_tz":-480,"elapsed":4977,"user":{"displayName":"Shem Lawalata","userId":"13541090692546704517"}},"outputId":"6d873427-2478-4a13-d469-866c37478d59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample PtID mappings:\n","Demographic PtID: 93 → CGM patterns: [93_, 2093_]\n","Demographic PtID: 93 → CGM patterns: [93_, 2093_]\n","Demographic PtID: 93 → CGM patterns: [93_, 2093_]\n","Demographic PtID: 93 → CGM patterns: [93_, 2093_]\n","Demographic PtID: 93 → CGM patterns: [93_, 2093_]\n","\n","Enhanced demographic data saved to /content/drive/MyDrive/Digital Health/T1_data_time_trial/Wadwa2023_demographic_with_groups.csv\n","\n","Trial participation summary:\n","In_trial\n","No    370\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","import zipfile\n","\n","\n","\n","# Configuration\n","base_path = '/content/drive/MyDrive/Digital Health/T1_data_time_trial'\n","demographic_path = f'{base_path}/Brown2019_demographic_with_groups.csv'  # Contains existing HbA1c\n","trial_zip_path = f'{base_path}/Brown2019.zip'\n","output_path = f'{base_path}/Brown2019_demographic_with_groups.csv'\n","\n","df = pd.read_csv(demographic_path)\n","print(f\"Loaded demographic data with {len(df)} subjects\")\n","\n","# Check HbA1c column\n","if 'hba1c' not in df.columns:\n","    raise ValueError(\"HbA1c column not found in demographic data\")\n","\n","# Function to convert PtID to CGM file format\n","def ptid_to_cgm_patterns(ptid):\n","    \"\"\"Generate all possible CGM filename patterns for a PtID\"\"\"\n","    ptid = int(ptid)\n","    return [\n","        f\"{ptid}_\",        # Original format (1_)\n","        f\"2{ptid:03d}_\",   # 2xxx format (2001_)\n","        f\"5{ptid:03d}_\"    # 5xxx format (5001_)\n","    ]\n","\n","# Function to get CGM readings from zip\n","def get_cgm_readings(ptid):\n","    \"\"\"Extract all CGM readings for a patient from zip\"\"\"\n","    patterns = ptid_to_cgm_patterns(ptid)\n","    readings = []\n","\n","    try:\n","        with zipfile.ZipFile(trial_zip_path) as z:\n","            for pattern in patterns:\n","                for file in z.namelist():\n","                    if (file.startswith(pattern) and\n","                        file.endswith('.npy') and\n","                        not '_time.npy' in file):\n","                        with z.open(file) as f:\n","                            data = np.load(f)\n","                            valid = data[~np.isnan(data)]\n","                            readings.extend(valid)\n","    except Exception as e:\n","        print(f\"Error processing PtID {ptid}: {str(e)}\")\n","\n","    return readings\n","\n","# Process missing HbA1c\n","missing_mask = df['hba1c'].isna()\n","print(f\"\\nFound {missing_mask.sum()} subjects with missing HbA1c\")\n","\n","if missing_mask.any():\n","    df['Estimated_hba1c'] = np.nan\n","    df['CGM_Readings_Used'] = 0\n","\n","    for idx, row in df[missing_mask].iterrows():\n","        ptid = row['PtID']\n","        readings = get_cgm_readings(ptid)\n","\n","        if readings:\n","            mean_glucose = np.mean(readings)\n","            estimated = (mean_glucose + 46.7) / 28.7\n","            df.at[idx, 'Estimated_hba1c'] = estimated\n","            df.at[idx, 'CGM_Readings_Used'] = len(readings)\n","            print(f\"PtID {ptid}: Estimated {estimated:.2f}% from {len(readings)} readings\")\n","\n","    # Create final combined column\n","    df['Final_hba1c'] = df['hba1c'].combine_first(df['Estimated_hba1c'])\n","else:\n","    df['Final_hba1c'] = df['hba1c']\n","\n","# Add clinical groups\n","def get_hba1c_group(value):\n","    if pd.isna(value): return 'Unknown'\n","    value = float(value)\n","    if value < 7: return '<7%'\n","    if value < 8.5: return '7-8.5%'\n","    return '≥8.5%'\n","\n","df['hba1c_Group'] = df['Final_hba1c'].apply(get_hba1c_group)\n","\n","# Save results\n","df.to_csv(output_path, index=False)\n","\n","# Summary report\n","print(\"\\nFinal Summary:\")\n","print(\"=\" * 40)\n","print(f\"Subjects with lab HbA1c: {len(df) - missing_mask.sum()}\")\n","print(f\"Subjects with estimated HbA1c: {df['Estimated_hba1c'].notna().sum()}\")\n","print(f\"Subjects still missing HbA1c: {df['Final_hba1c'].isna().sum()}\")\n","print(\"\\nHbA1c Group Distribution:\")\n","print(df['hba1c_Group'].value_counts(dropna=False))\n","print(f\"\\nResults saved to {output_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":656},"id":"3sE-2_Cx2RCN","executionInfo":{"status":"error","timestamp":1746473096940,"user_tz":-480,"elapsed":307,"user":{"displayName":"Shem Lawalata","userId":"13541090692546704517"}},"outputId":"dcbae9d6-8f09-444a-c262-2d0d2700d13c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded demographic data with 1096 subjects\n","\n","Found 0 subjects with missing HbA1c\n","\n","Final Summary:\n","========================================\n","Subjects with lab HbA1c: 1096\n"]},{"output_type":"error","ename":"KeyError","evalue":"'Estimated_hba1c'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Estimated_hba1c'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-720fa745f601>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Subjects with lab HbA1c: {len(df) - missing_mask.sum()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Subjects with estimated HbA1c: {df['Estimated_hba1c'].notna().sum()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Subjects still missing HbA1c: {df['Final_hba1c'].isna().sum()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nHbA1c Group Distribution:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Estimated_hba1c'"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","file_path = '/content/drive/MyDrive/Digital Health/T1_data_time_trial/Wadwa2023_demographic_with_groups.csv'\n","df = pd.read_csv(file_path)\n","#df = df.iloc[:, :-4]\n","df = df.drop(df.columns[-5], axis=1) #5 from behind\n","df.to_csv('/content/drive/MyDrive/Digital Health/T1_data_time_trial/Wadwa2023_demographic_with_groups.csv', index=False)"],"metadata":{"id":"tNPWsU6Z5F4L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#to check t1 granada\n","import pandas as pd\n","import numpy as np\n","import zipfile\n","from google.colab import drive\n","\n","\n","\n","# Configuration\n","base_path = '/content/drive/MyDrive/Digital Health/T1_data_time_trial'\n","demographic_path = f'{base_path}/T1_granada_demographic.csv'  # Contains 'Value' column with HbA1c\n","trial_zip_path = f'{base_path}/T1_granada_missing.zip'      # Contains numeric ID CGM files\n","output_path = f'{base_path}/T1_granada_demographic_with_groups.csv'\n","\n","# Load demographic data\n","df = pd.read_csv(demographic_path)\n","print(f\"Loaded data with {len(df)} subjects\")\n","print(\"Existing HbA1c values:\", df['Value'].notna().sum(), \"| Missing:\", df['Value'].isna().sum())\n","\n","# Extract numeric ID from Patient_ID (LIB123 → 123)\n","df['NumericID'] = df['Patient_ID'].str.extract('(\\d+)').astype(int)\n","\n","# Function to estimate HbA1c from CGM\n","def estimate_from_cgm(numeric_id):\n","    \"\"\"Calculate mean glucose from CGM data and convert to HbA1c estimate\"\"\"\n","    readings = []\n","    try:\n","        with zipfile.ZipFile(trial_zip_path) as z:\n","            pattern = f\"{numeric_id}_\"  # Looks for files like \"123_*.npy\"\n","            for file in z.namelist():\n","                if file.startswith(pattern) and file.endswith('.npy') and not '_time.npy' in file:\n","                    with z.open(file) as f:\n","                        data = np.load(f)\n","                        valid = data[~np.isnan(data)]\n","                        readings.extend(valid)\n","    except Exception as e:\n","        print(f\"Error processing {numeric_id}: {str(e)}\")\n","\n","    if readings:\n","        mean_glucose = np.mean(readings)\n","        return (mean_glucose + 46.7) / 28.7  # Standard formula\n","    return np.nan\n","\n","# Process missing HbA1c values\n","missing_mask = df['Value'].isna()\n","print(f\"\\nEstimating for {missing_mask.sum()} missing values...\")\n","\n","if missing_mask.any():\n","    df['Estimated_HbA1c'] = np.nan\n","    for idx, row in df[missing_mask].iterrows():\n","        numeric_id = row['NumericID']\n","        estimated = estimate_from_cgm(numeric_id)\n","        if not np.isnan(estimated):\n","            df.at[idx, 'Estimated_HbA1c'] = estimated\n","            print(f\"{row['Patient_ID']}: Estimated {estimated:.2f}%\")\n","\n","    # Create final combined column\n","    df['Final_HbA1c'] = df['Value'].combine_first(df['Estimated_HbA1c'])\n","else:\n","    df['Final_HbA1c'] = df['Value']\n","\n","# Save results (drop temporary NumericID column)\n","df.drop('NumericID', axis=1).to_csv(output_path, index=False)\n","\n","# Final report\n","print(\"\\nResults Summary:\")\n","print(\"=\" * 40)\n","print(f\"Original HbA1c values: {df['Value'].notna().sum()}\")\n","print(f\"Estimated HbA1c values: {df['Estimated_HbA1c'].notna().sum()}\")\n","print(f\"Still missing: {df['Final_HbA1c'].isna().sum()}\")\n","print(f\"\\nSaved complete data to: {output_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":554},"id":"l97-XVEApBag","executionInfo":{"status":"error","timestamp":1746847763371,"user_tz":-480,"elapsed":69,"user":{"displayName":"Shem Lawalata","userId":"13541090692546704517"}},"outputId":"7e0b2206-aaf9-4dc1-bd3d-9087a735ec86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded data with 451 subjects\n"]},{"output_type":"error","ename":"KeyError","evalue":"'Value'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Value'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-32a586c2f00f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemographic_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loaded data with {len(df)} subjects\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Existing HbA1c values:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"| Missing:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Extract numeric ID from Patient_ID (LIB123 → 123)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Value'"]}]},{"cell_type":"code","source":["#for checking tamborlane id 303\n","import pandas as pd\n","import zipfile\n","from google.colab import drive\n","\n","\n","# Configuration\n","base_path = '/content/drive/MyDrive/Digital Health/T1_data_time_trial'\n","cgm_zip_path = f'{base_path}/Tamborlane2008.zip'\n","subject_id = 303  # The ID you want to check\n","\n","\n","\n","# 2. Check in CGM zip file\n","print(\"\\nChecking CGM data...\")\n","try:\n","    with zipfile.ZipFile(cgm_zip_path) as z:\n","        # Look for files with pattern \"303_*.npy\" or \"LIB303_*.npy\"\n","        cgm_files = [f for f in z.namelist()\n","                    if (f.startswith(f'{subject_id}_') or\n","                        f.startswith(f'LIB{subject_id}_'))\n","                    and f.endswith('.npy')\n","                    and not '_time.npy' in f]\n","\n","        print(f\"CGM files found: {len(cgm_files)}\")\n","        if cgm_files:\n","            print(\"Matching CGM files:\")\n","            for file in cgm_files[:3]:  # Show first 3 files if many exist\n","                print(f\" - {file}\")\n","            if len(cgm_files) > 3:\n","                print(f\" - ...and {len(cgm_files)-3} more\")\n","except Exception as e:\n","    print(f\"Error reading CGM zip: {str(e)}\")\n","\n","print(\"\\nCheck complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fW7bK4WjKxlI","executionInfo":{"status":"ok","timestamp":1746847479699,"user_tz":-480,"elapsed":58,"user":{"displayName":"Shem Lawalata","userId":"13541090692546704517"}},"outputId":"f9a778b6-0310-4684-95b3-644a3133908f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Checking CGM data...\n","CGM files found: 2\n","Matching CGM files:\n"," - 303_1.npy\n"," - 303_0.npy\n","\n","Check complete.\n"]}]},{"cell_type":"code","source":["#tamborlane hba1c fill\n","import pandas as pd\n","import numpy as np\n","import zipfile\n","\n","\n","\n","# Configuration\n","base_path = '/content/drive/MyDrive/Digital Health/T1_data_time_trial'\n","demographic_path = f'{base_path}/Tamborlane2008_demographic.csv'\n","cgm_zip_path = f'{base_path}/Tamborlane2008.zip'\n","output_path = f'{base_path}/Tamborlane2008_demographic_update.csv'\n","target_ptid = 303  # The specific PtID we're checking\n","\n","# Load demographic data\n","df = pd.read_csv(demographic_path)\n","\n","# Function to calculate HbA1c from CGM data\n","def calculate_hba1c_from_cgm(ptid):\n","    \"\"\"Calculate HbA1c from CGM data using standard formula\"\"\"\n","    glucose_readings = []\n","    try:\n","        with zipfile.ZipFile(cgm_zip_path) as z:\n","            # Check both possible ID formats\n","            patterns = [f\"{ptid}_\", f\"LIB{ptid}_\"]\n","\n","            for pattern in patterns:\n","                for file in z.namelist():\n","                    if (file.startswith(pattern) and\n","                        file.endswith('.npy') and\n","                        not '_time.npy' in file):\n","                        with z.open(file) as f:\n","                            data = np.load(f)\n","                            valid_values = data[~np.isnan(data)]\n","                            glucose_readings.extend(valid_values)\n","\n","        if glucose_readings:\n","            mean_glucose = np.mean(glucose_readings)\n","            return (mean_glucose + 46.7) / 28.7  # Standard formula\n","        return np.nan\n","    except Exception as e:\n","        print(f\"Error processing PtID {ptid}: {str(e)}\")\n","        return np.nan\n","\n","# Check for PtID 303 with missing LabA1cResult but having CGM data\n","def process_ptid_303():\n","    # Find the specific patient record\n","    ptid_mask = (df['PtID'].astype(str) == str(target_ptid)) | \\\n","                (df['PtID'].astype(str) == f'LIB{target_ptid}')\n","\n","    if not ptid_mask.any():\n","        print(f\"PtID {target_ptid} not found in demographic data\")\n","        return\n","\n","    patient_data = df[ptid_mask]\n","    print(f\"Found PtID {target_ptid} in demographic data\")\n","\n","    # Check if LabA1cResult is missing\n","    if patient_data['LabA1cResult'].isna().any():\n","        print(\"LabA1cResult is missing - checking for CGM data...\")\n","\n","        # Calculate HbA1c from CGM\n","        estimated_hba1c = calculate_hba1c_from_cgm(target_ptid)\n","\n","        if not np.isnan(estimated_hba1c):\n","            print(f\"Estimated HbA1c: {estimated_hba1c:.2f}%\")\n","\n","            # Update the dataframe\n","            idx = patient_data.index[0]\n","            df.at[idx, 'LabA1cResult'] = estimated_hba1c\n","\n","            # Update a1c_mean_group based on the new value\n","            if estimated_hba1c < 7:\n","                df.at[idx, 'a1c_mean_group'] = '<7%'\n","            elif estimated_hba1c < 8.5:\n","                df.at[idx, 'a1c_mean_group'] = '7-8.5%'\n","            else:\n","                df.at[idx, 'a1c_mean_group'] = '≥8.5%'\n","\n","            print(\"Successfully updated LabA1cResult and a1c_mean_group\")\n","        else:\n","            print(\"No CGM data available for estimation\")\n","    else:\n","        print(f\"LabA1cResult exists: {patient_data['LabA1cResult'].values[0]}%\")\n","\n","# Execute the processing\n","process_ptid_303()\n","\n","# Save the updated dataframe\n","df.to_csv(output_path, index=False)\n","print(f\"\\nUpdated demographic data saved to: {output_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9xH_h0BFQyfz","executionInfo":{"status":"ok","timestamp":1746848206658,"user_tz":-480,"elapsed":1295,"user":{"displayName":"Shem Lawalata","userId":"13541090692546704517"}},"outputId":"3ba0ef2a-cbb6-47ef-ca8e-9bfbf05a46df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found PtID 303 in demographic data\n","LabA1cResult is missing - checking for CGM data...\n","Estimated HbA1c: 6.86%\n","Successfully updated LabA1cResult and a1c_mean_group\n","\n","Updated demographic data saved to: /content/drive/MyDrive/Digital Health/T1_data_time_trial/Tamborlane2008_demographic_update.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import zipfile\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Configuration\n","base_path = '/content/drive/MyDrive/Digital Health/T1_data_time_trial'\n","demographic_path = f'{base_path}/brown2019_demographics.csv'\n","hba1c_path = f'{base_path}/brown2019_hba1c.csv'\n","cgm_zip_path = f'{base_path}/Brown2019.zip'\n","output_path = f'{base_path}/brown_demographic_with_avg_hba1c.csv'\n","\n","# Load data\n","demo_df = pd.read_csv(demographic_path)\n","hba1c_df = pd.read_csv(hba1c_path)\n","\n","# 1. Calculate average HbA1c per PtID\n","print(\"Calculating average HbA1c from hba1c file...\")\n","avg_hba1c = hba1c_df.groupby('PtID')['hba1c'].mean().reset_index()\n","avg_hba1c.columns = ['PtID', 'avg_hba1c']\n","\n","# 2. Merge with demographic data\n","print(\"\\nMerging with demographic data...\")\n","merged_df = pd.merge(\n","    demo_df,\n","    avg_hba1c,\n","    on='PtID',\n","    how='left'\n",")\n","\n","# 3. Add clinical groupings\n","def get_hba1c_group(value):\n","    if pd.isna(value): return 'Unknown'\n","    value = float(value)\n","    if value < 7: return '<7%'\n","    if value < 8.5: return '7-8.5%'\n","    return '≥8.5%'\n","\n","merged_df['hba1c_Group'] = merged_df['avg_hba1c'].apply(get_hba1c_group)\n","\n","def get_age_group(age):\n","    if pd.isna(age): return 'Unknown'\n","    age = float(age)\n","    if age < 10: return '<10'\n","    if age < 20: return '10-19'\n","    if age < 65: return '20-64'\n","    return '≥65'\n","\n","merged_df['age_group'] = merged_df['AgeAtEnrollment'].apply(get_age_group)\n","\n","# 4. Check CGM Participation - Updated for 5xxx.0_x.npy format\n","def check_cgm_participation(zip_file):\n","    \"\"\"Extract IDs from filenames in format 5xxx.0_x.npy\"\"\"\n","    cgm_ids = set()\n","    for file in zip_file.namelist():\n","        if file.endswith('.npy') and not '_time.npy' in file:\n","            try:\n","                # Extract base filename (e.g., \"5001.0_4.npy\" → \"5001\")\n","                base_name = file.split('/')[-1]  # Handle subdirectories\n","                ptid = int(base_name.split('.')[0])  # Get the integer part before first dot\n","                cgm_ids.add(ptid)\n","            except (ValueError, IndexError):\n","                print(f\"Couldn't parse ID from: {file}\")\n","                continue\n","    return cgm_ids\n","\n","print(\"\\nChecking CGM participation...\")\n","with zipfile.ZipFile(cgm_zip_path) as z:\n","    cgm_participants = check_cgm_participation(z)\n","    print(f\"Found {len(cgm_participants)} unique subjects with CGM data\")\n","    merged_df['has_cgm'] = merged_df['PtID'].isin(cgm_participants)\n","\n","    # Print verification info\n","    print(\"\\nFirst 5 CGM files found:\")\n","    for file in z.namelist()[:5]:\n","        print(file)\n","\n","# Identify missing subjects\n","missing_cgm = merged_df[~merged_df['has_cgm']]['PtID'].unique()\n","print(f\"\\nSubjects without CGM data ({len(missing_cgm)}): {sorted(missing_cgm)}\")\n","\n","# Verify with sample\n","sample_check = merged_df[['PtID', 'has_cgm']].sample(5)\n","print(\"\\nSample verification:\")\n","print(sample_check)\n","\n","# Summary report\n","print(\"\\nFinal Summary:\")\n","print(\"=\" * 40)\n","print(f\"Total subjects: {len(merged_df)}\")\n","print(f\"Subjects with HbA1c data: {merged_df['avg_hba1c'].notna().sum()}\")\n","print(f\"Subjects with CGM data: {merged_df['has_cgm'].sum()}\")\n","print(\"\\nHbA1c Group Distribution:\")\n","print(merged_df['hba1c_Group'].value_counts(dropna=False))\n","print(\"\\nAge Group Distribution:\")\n","print(merged_df['age_group'].value_counts(dropna=False))\n","\n","# Save results\n","merged_df.to_csv(output_path, index=False)\n","print(f\"\\nSaved to: {output_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iPpx8xK_gNhk","executionInfo":{"status":"ok","timestamp":1746856219534,"user_tz":-480,"elapsed":2679,"user":{"displayName":"Shem Lawalata","userId":"13541090692546704517"}},"outputId":"0d1f8b74-9720-457f-bcff-a7c0726c43ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Calculating average HbA1c from hba1c file...\n","\n","Merging with demographic data...\n","\n","Checking CGM participation...\n","Found 167 unique subjects with CGM data\n","\n","First 5 CGM files found:\n","5050.0_13.npy\n","5140.0_5.npy\n","5045.0_5.npy\n","5164.0_1.npy\n","5095.0_4.npy\n","\n","Subjects without CGM data (3): [np.int64(5033), np.int64(5068), np.int64(5084)]\n","\n","Sample verification:\n","     PtID  has_cgm\n","107  5109     True\n","1    5002     True\n","67   5069     True\n","56   5058     True\n","27   5029     True\n","\n","Final Summary:\n","========================================\n","Total subjects: 170\n","Subjects with HbA1c data: 170\n","Subjects with CGM data: 167\n","\n","HbA1c Group Distribution:\n","hba1c_Group\n","7-8.5%    96\n","<7%       64\n","≥8.5%     10\n","Name: count, dtype: int64\n","\n","Age Group Distribution:\n","age_group\n","20-64    116\n","10-19     51\n","≥65        3\n","Name: count, dtype: int64\n","\n","Saved to: /content/drive/MyDrive/Digital Health/T1_data_time_trial/brown_demographic_with_avg_hba1c.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import zipfile\n","\n","# Configuration\n","base_path = '/content/drive/MyDrive/Digital Health/T1_data_time_trial'\n","demographic_path = f'{base_path}/wadwa2023_demographic.csv'\n","hba1c_path = f'{base_path}/Wadwa_hba1c.csv'\n","cgm_zip_path = f'{base_path}/wadwa2023.zip'\n","output_path = f'{base_path}/wadwa_demographic_with_avg_hba1c.csv'\n","\n","# Load data\n","demo_df = pd.read_csv(demographic_path)\n","hba1c_df = pd.read_csv(hba1c_path)\n","\n","def calculate_hba1c_from_cgm(ptid):\n","    \"\"\"Calculate HbA1c from CGM data - handles both '101.npy' and '101_2.npy' formats\"\"\"\n","    glucose_readings = []\n","    try:\n","        with zipfile.ZipFile(cgm_zip_path) as z:\n","            # Try both filename patterns:\n","            patterns = [f\"{ptid}.npy\", f\"{ptid}_\"]\n","\n","            for pattern in patterns:\n","                for file in z.namelist():\n","                    if (file.startswith(pattern) and file.endswith('.npy')) and not '_time.npy' in file:\n","                        with z.open(file) as f:\n","                            data = np.load(f)\n","                            valid_values = data[~np.isnan(data)]\n","                            glucose_readings.extend(valid_values)\n","\n","        if glucose_readings:\n","            mean_glucose = np.mean(glucose_readings)\n","            return (mean_glucose + 46.7) / 28.7\n","        return np.nan\n","    except Exception as e:\n","        print(f\"Error processing PtID {ptid}: {str(e)}\")\n","        return np.nan\n","\n","def check_cgm_participation(zip_file):\n","    \"\"\"Updated to match both ID formats\"\"\"\n","    cgm_ids = set()\n","    for file in zip_file.namelist():\n","        if file.endswith('.npy') and not '_time.npy' in file:\n","            try:\n","                # Extract ID from either \"101.npy\" or \"101_2.npy\"\n","                base = file.split('/')[-1].split('_')[0].replace('.npy','')\n","                cgm_ids.add(int(base))\n","            except ValueError:\n","                continue\n","    return cgm_ids\n","\n","# 1. Process individual HbA1c measurements\n","print(\"Processing individual HbA1c measurements...\")\n","filled_hba1c_df = hba1c_df.copy()\n","missing_measurements = filled_hba1c_df[filled_hba1c_df['hba1c'].isna()]\n","\n","print(f\"\\nFound {len(missing_measurements)} missing measurements for these IDs:\")\n","print(missing_measurements['PtID'].unique())\n","\n","# Track which IDs we filled\n","filled_from_cgm = []\n","still_missing = []\n","\n","for idx, row in missing_measurements.iterrows():\n","    ptid = row['PtID']\n","    cgm_hba1c = calculate_hba1c_from_cgm(ptid)\n","    if not np.isnan(cgm_hba1c):\n","        filled_hba1c_df.at[idx, 'hba1c'] = cgm_hba1c\n","        filled_from_cgm.append(ptid)\n","    else:\n","        still_missing.append(ptid)\n","\n","print(\"\\nSuccessfully filled HbA1c from CGM for these IDs:\")\n","print(np.unique(filled_from_cgm))\n","\n","print(\"\\nStill missing HbA1c (no CGM data available) for these IDs:\")\n","print(np.unique(still_missing))\n","\n","# 2. Calculate average HbA1c per subject\n","print(\"\\nCalculating average HbA1c per subject...\")\n","avg_hba1c = filled_hba1c_df.groupby('PtID')['hba1c'].mean().reset_index()\n","avg_hba1c.columns = ['PtID', 'avg_hba1c']\n","\n","# Identify subjects still missing HbA1c\n","missing_subjects = avg_hba1c[avg_hba1c['avg_hba1c'].isna()]['PtID'].unique()\n","print(f\"\\nSubjects with no HbA1c data at all: {missing_subjects}\")\n","\n","# [Rest of the merging, grouping and saving code remains the same]\n","\n","# 3. Identify subjects still missing HbA1c (no measurements at all)\n","missing_subjects = avg_hba1c[avg_hba1c['avg_hba1c'].isna()]['PtID'].unique()\n","print(f\"\\nFound {len(missing_subjects)} subjects with no HbA1c data\")\n","\n","# 4. Calculate HbA1c from CGM for completely missing subjects\n","print(\"\\nCalculating HbA1c for subjects with no measurements...\")\n","for ptid in missing_subjects:\n","    cgm_hba1c = calculate_hba1c_from_cgm(ptid)\n","    if not np.isnan(cgm_hba1c):\n","        # Add new row with CGM-estimated value\n","        avg_hba1c.loc[len(avg_hba1c)] = [ptid, cgm_hba1c]\n","        print(f\"Estimated HbA1c for PtID {ptid}: {cgm_hba1c:.2f}%\")\n","\n","# [Previous code remains the same until the missing measurements section]\n","\n","# 1. Process individual HbA1c measurements\n","print(\"Processing individual HbA1c measurements...\")\n","\n","# Create a copy to store filled values\n","filled_hba1c_df = hba1c_df.copy()\n","\n","# Identify missing individual measurements\n","missing_measurements = filled_hba1c_df[filled_hba1c_df['hba1c'].isna()]\n","print(f\"\\nFound {len(missing_measurements)} missing individual HbA1c measurements for these subjects:\")\n","print(missing_measurements[['PtID', 'hba1c']].to_string(index=False))  # Show PtIDs with missing values\n","\n","# [Rest of the code remains the same]\n","\n","# 5. Merge with demographic data\n","print(\"\\nMerging with demographic data...\")\n","merged_df = pd.merge(\n","    demo_df,\n","    avg_hba1c,\n","    on='PtID',\n","    how='left'\n",")\n","\n","# 6. Add clinical groupings\n","def get_hba1c_group(value):\n","    if pd.isna(value): return 'Unknown'\n","    value = float(value)\n","    if value < 7: return '<7%'\n","    if value < 8.5: return '7-8.5%'\n","    return '≥8.5%'\n","\n","merged_df['hba1c_Group'] = merged_df['avg_hba1c'].apply(get_hba1c_group)\n","\n","def get_age_group(age):\n","    if pd.isna(age): return 'Unknown'\n","    age = float(age)\n","    if age < 10: return '<10'\n","    if age < 20: return '10-19'\n","    if age < 65: return '20-64'\n","    return '≥65'\n","\n","merged_df['age_group'] = merged_df['AgeAsofEnrollDt'].apply(get_age_group)\n","\n","# 7. Check CGM Participation\n","def check_cgm_participation(zip_file):\n","    \"\"\"Extract IDs from filenames in format 5xxx.0_x.npy\"\"\"\n","    cgm_ids = set()\n","    for file in zip_file.namelist():\n","        if file.endswith('.npy') and not '_time.npy' in file:\n","            try:\n","                base_name = file.split('/')[-1]\n","                ptid = int(base_name.split('.')[0])\n","                cgm_ids.add(ptid)\n","            except (ValueError, IndexError):\n","                continue\n","    return cgm_ids\n","\n","print(\"\\nChecking CGM participation...\")\n","with zipfile.ZipFile(cgm_zip_path) as z:\n","    cgm_participants = check_cgm_participation(z)\n","    print(f\"Found {len(cgm_participants)} unique subjects with CGM data\")\n","    merged_df['has_cgm'] = merged_df['PtID'].isin(cgm_participants)\n","\n","# Final Summary\n","print(\"\\nFinal Summary:\")\n","print(\"=\" * 40)\n","print(f\"Total subjects: {len(merged_df)}\")\n","print(f\"Subjects with original HbA1c measurements: {len(hba1c_df['PtID'].unique())}\")\n","print(f\"Missing measurements filled from CGM: {len(missing_measurements) - filled_hba1c_df['hba1c'].isna().sum()}\")\n","print(f\"Subjects with CGM-estimated HbA1c (no measurements): {len(missing_subjects) - merged_df['avg_hba1c'].isna().sum()}\")\n","print(f\"Subjects still missing HbA1c: {merged_df['avg_hba1c'].isna().sum()}\")\n","print(\"\\nHbA1c Group Distribution:\")\n","print(merged_df['hba1c_Group'].value_counts(dropna=False))\n","print(\"\\nAge Group Distribution:\")\n","print(merged_df['age_group'].value_counts(dropna=False))\n","\n","# Save results\n","merged_df.to_csv(output_path, index=False)\n","print(f\"\\nSaved to: {output_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5r9DS883BWSJ","executionInfo":{"status":"ok","timestamp":1746881239734,"user_tz":-480,"elapsed":222,"user":{"displayName":"Shem Lawalata","userId":"13541090692546704517"}},"outputId":"9c234ddd-68c3-44b7-ede5-f039f4180b9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing individual HbA1c measurements...\n","\n","Found 19 missing measurements for these IDs:\n","[ 50  47  59  77  81  91  82  44  15  40  37  65  11  19  68 101  97]\n","\n","Successfully filled HbA1c from CGM for these IDs:\n","[]\n","\n","Still missing HbA1c (no CGM data available) for these IDs:\n","[ 11  15  19  37  40  44  47  50  59  65  68  77  81  82  91  97 101]\n","\n","Calculating average HbA1c per subject...\n","\n","Subjects with no HbA1c data at all: []\n","\n","Found 0 subjects with no HbA1c data\n","\n","Calculating HbA1c for subjects with no measurements...\n","Processing individual HbA1c measurements...\n","\n","Found 19 missing individual HbA1c measurements for these subjects:\n"," PtID  hba1c\n","   50    NaN\n","   47    NaN\n","   59    NaN\n","   77    NaN\n","   81    NaN\n","   91    NaN\n","   82    NaN\n","   44    NaN\n","   15    NaN\n","   40    NaN\n","   37    NaN\n","   65    NaN\n","   11    NaN\n","   65    NaN\n","   19    NaN\n","   68    NaN\n","  101    NaN\n","   65    NaN\n","   97    NaN\n","\n","Merging with demographic data...\n","\n","Checking CGM participation...\n","Found 861 unique subjects with CGM data\n","\n","Final Summary:\n","========================================\n","Total subjects: 109\n","Subjects with original HbA1c measurements: 102\n","Missing measurements filled from CGM: 0\n","Subjects with CGM-estimated HbA1c (no measurements): -7\n","Subjects still missing HbA1c: 7\n","\n","HbA1c Group Distribution:\n","hba1c_Group\n","7-8.5%     56\n","<7%        40\n","Unknown     7\n","≥8.5%       6\n","Name: count, dtype: int64\n","\n","Age Group Distribution:\n","age_group\n","<10    109\n","Name: count, dtype: int64\n","\n","Saved to: /content/drive/MyDrive/Digital Health/T1_data_time_trial/wadwa_demographic_with_avg_hba1c.csv\n"]}]},{"cell_type":"code","source":["#t1 missing hbaqc val and id\n","import pandas as pd\n","import numpy as np\n","import zipfile\n","\n","\n","# Configuration\n","base_path = '/content/drive/MyDrive/Digital Health/T1_data_time_trial'\n","demographic_path = f'{base_path}/T1_granada_demographic_with_groups.csv'\n","cgm_zip_path = f'{base_path}/T1_granada.zip'\n","missing_zip_path = f'{base_path}/T1_granada_missing (1).zip'\n","time_zip_path = f'{base_path}/T1_granada_time.zip'\n","output_path = f'{base_path}/T1_granada_demographic_with_groups.csv'\n","\n","# Load demographic data\n","print(\"Loading demographic data...\")\n","demo_df = pd.read_csv(demographic_path)\n","\n","# Identify patients with missing HbA1c\n","missing_hba1c_patients = demo_df[demo_df['Value'].isna()]['Patient_ID'].unique()\n","print(f\"\\nFound {len(missing_hba1c_patients)} patients with missing HbA1c:\")\n","print(missing_hba1c_patients)\n","\n","# Function to examine ZIP file contents\n","def examine_zip(zip_path):\n","    print(f\"\\nExamining {zip_path.split('/')[-1]} contents:\")\n","    with zipfile.ZipFile(zip_path) as z:\n","        for i, file in enumerate(z.namelist()[:5]):\n","            print(f\"  {file}\")\n","        print(f\"  ... (showing first 5 of {len(z.namelist())} files)\")\n","\n","# Examine file formats\n","examine_zip(cgm_zip_path)\n","examine_zip(missing_zip_path)\n","examine_zip(time_zip_path)\n","\n","# Function to calculate HbA1c from CGM\n","import os\n","\n","def calculate_hba1c_from_cgm(ptid):\n","    \"\"\"Calculate HbA1c from CGM data using standard formula\"\"\"\n","    glucose_readings = []\n","\n","    # Extract numeric part of patient ID if prefixed\n","    numeric_id = ''.join(filter(str.isdigit, ptid))\n","\n","    # Patterns to match filenames\n","    possible_ids = [ptid, numeric_id, f\"GR{numeric_id}\"]\n","\n","    for zip_path in [cgm_zip_path, missing_zip_path]:\n","        try:\n","            with zipfile.ZipFile(zip_path) as z:\n","                for file in z.namelist():\n","                    basename = os.path.basename(file)\n","                    if basename.endswith('.npy') and '_time.npy' not in basename:\n","                        for pid in possible_ids:\n","                            if basename.startswith(pid):\n","                                with z.open(file) as f:\n","                                    data = np.load(f)\n","                                    valid_values = data[~np.isnan(data)]\n","                                    glucose_readings.extend(valid_values)\n","                                break  # No need to check other patterns if one matched\n","        except Exception as e:\n","            print(f\"Error reading {zip_path} for PtID {ptid}: {str(e)}\")\n","\n","    if glucose_readings:\n","        mean_glucose = np.mean(glucose_readings)\n","        estimated_hba1c = (mean_glucose + 46.7) / 28.7\n","        print(f\"  Calculated HbA1c {estimated_hba1c:.2f}% for Patient_ID {ptid}\")\n","        return estimated_hba1c\n","\n","    return np.nan\n","\n","\n","\n","# Process missing HbA1c values\n","print(\"\\nProcessing missing HbA1c values...\")\n","filled_count = 0\n","\n","for ptid in missing_hba1c_patients:\n","    print(f\"\\nProcessing Patient_ID {ptid}:\")\n","    hba1c = calculate_hba1c_from_cgm(ptid)\n","\n","    if not np.isnan(hba1c):\n","        demo_df.loc[demo_df['Patient_ID'] == ptid, 'Value'] = hba1c\n","        demo_df.loc[demo_df['Patient_ID'] == ptid, 'hba1c_source'] = 'CGM-estimated'\n","        filled_count += 1\n","        print(f\"  Successfully filled missing HbA1c\")\n","    else:\n","        print(f\"  Could not calculate HbA1c - no CGM data available\")\n","\n","# Add clinical groupings\n","def get_hba1c_group(value):\n","    if pd.isna(value): return 'Unknown'\n","    value = float(value)\n","    if value < 7: return '<7%'\n","    if value < 8.5: return '7-8.5%'\n","    return '≥8.5%'\n","\n","demo_df['a1c_mean_group'] = demo_df['Value'].apply(get_hba1c_group)\n","\n","# Final summary\n","print(\"\\nFinal Summary:\")\n","print(\"=\"*50)\n","print(f\"Total patients: {len(demo_df)}\")\n","print(f\"Patients with missing HbA1c: {len(missing_hba1c_patients)}\")\n","print(f\"Successfully filled from CGM: {filled_count}\")\n","print(f\"Still missing: {len(missing_hba1c_patients) - filled_count}\")\n","print(\"\\nHbA1c Group Distribution:\")\n","print(demo_df['a1c_mean_group'].value_counts(dropna=False))\n","\n","# Save results\n","demo_df.to_csv(output_path, index=False)\n","print(f\"\\nSaved results to: {output_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZQbwlVxcetcx","executionInfo":{"status":"ok","timestamp":1747272614088,"user_tz":-480,"elapsed":5503,"user":{"displayName":"Shem Lawalata","userId":"13541090692546704517"}},"outputId":"3c976396-bc96-42ac-90bf-d9d0cf3238db"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading demographic data...\n","\n","Found 16 patients with missing HbA1c:\n","['LIB193263' 'LIB193264' 'LIB193269' 'LIB193280' 'LIB193511' 'LIB193521'\n"," 'LIB193536' 'LIB193650' 'LIB193764' 'LIB193769' 'LIB193801' 'LIB193806'\n"," 'LIB193812' 'LIB193835' 'LIB193865' 'LIB194063']\n","\n","Examining T1_granada.zip contents:\n","  T1_granada/193263_0.npy\n","  T1_granada/193263_1.npy\n","  T1_granada/193263_10.npy\n","  T1_granada/193263_11.npy\n","  T1_granada/193263_12.npy\n","  ... (showing first 5 of 13680 files)\n","\n","Examining T1_granada_missing (1).zip contents:\n","  T1_granada_missing/LIB193263.csv\n","  T1_granada_missing/LIB193266.csv\n","  T1_granada_missing/LIB193267.csv\n","  T1_granada_missing/LIB193269.csv\n","  T1_granada_missing/LIB193272.csv\n","  ... (showing first 5 of 594 files)\n","\n","Examining T1_granada_time.zip contents:\n","  T1_granada_time/193263_0_time.npy\n","  T1_granada_time/193263_1_time.npy\n","  T1_granada_time/193263_10_time.npy\n","  T1_granada_time/193263_11_time.npy\n","  T1_granada_time/193263_12_time.npy\n","  ... (showing first 5 of 13680 files)\n","\n","Processing missing HbA1c values...\n","\n","Processing Patient_ID LIB193263:\n","  Calculated HbA1c 7.80% for Patient_ID LIB193263\n","  Successfully filled missing HbA1c\n","\n","Processing Patient_ID LIB193264:\n","  Could not calculate HbA1c - no CGM data available\n","\n","Processing Patient_ID LIB193269:\n","  Calculated HbA1c 7.04% for Patient_ID LIB193269\n","  Successfully filled missing HbA1c\n","\n","Processing Patient_ID LIB193280:\n","  Calculated HbA1c 6.47% for Patient_ID LIB193280\n","  Successfully filled missing HbA1c\n","\n","Processing Patient_ID LIB193511:\n","  Calculated HbA1c 7.94% for Patient_ID LIB193511\n","  Successfully filled missing HbA1c\n","\n","Processing Patient_ID LIB193521:\n","  Calculated HbA1c 6.96% for Patient_ID LIB193521\n","  Successfully filled missing HbA1c\n","\n","Processing Patient_ID LIB193536:\n","  Calculated HbA1c 6.99% for Patient_ID LIB193536\n","  Successfully filled missing HbA1c\n","\n","Processing Patient_ID LIB193650:\n","  Could not calculate HbA1c - no CGM data available\n","\n","Processing Patient_ID LIB193764:\n","  Calculated HbA1c 6.97% for Patient_ID LIB193764\n","  Successfully filled missing HbA1c\n","\n","Processing Patient_ID LIB193769:\n","  Calculated HbA1c 8.46% for Patient_ID LIB193769\n","  Successfully filled missing HbA1c\n","\n","Processing Patient_ID LIB193801:\n","  Calculated HbA1c 6.75% for Patient_ID LIB193801\n","  Successfully filled missing HbA1c\n","\n","Processing Patient_ID LIB193806:\n","  Calculated HbA1c 7.36% for Patient_ID LIB193806\n","  Successfully filled missing HbA1c\n","\n","Processing Patient_ID LIB193812:\n","  Could not calculate HbA1c - no CGM data available\n","\n","Processing Patient_ID LIB193835:\n","  Calculated HbA1c 7.27% for Patient_ID LIB193835\n","  Successfully filled missing HbA1c\n","\n","Processing Patient_ID LIB193865:\n","  Calculated HbA1c 6.95% for Patient_ID LIB193865\n","  Successfully filled missing HbA1c\n","\n","Processing Patient_ID LIB194063:\n","  Calculated HbA1c 8.01% for Patient_ID LIB194063\n","  Successfully filled missing HbA1c\n","\n","Final Summary:\n","==================================================\n","Total patients: 736\n","Patients with missing HbA1c: 16\n","Successfully filled from CGM: 13\n","Still missing: 3\n","\n","HbA1c Group Distribution:\n","a1c_mean_group\n","7-8.5%     394\n","≥8.5%      184\n","<7%        155\n","Unknown      3\n","Name: count, dtype: int64\n","\n","Saved results to: /content/drive/MyDrive/Digital Health/T1_data_time_trial/T1_granada_demographic_with_groups.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import zipfile\n","import os\n","\n","# Configuration\n","base_path = '/content/drive/MyDrive/Digital Health/T1_data_time_trial'\n","demographic_path = f'{base_path}/T1_granada_demographic_with_groups.csv'\n","cgm_zip_path = f'{base_path}/T1_granada.zip'\n","missing_zip_path = f'{base_path}/T1_granada_missing (1).zip'\n","time_zip_path = f'{base_path}/T1_granada_time.zip'\n","output_path = f'{base_path}/T1_granada_demographic_with_groups.csv'\n","\n","csv_file_name = '193264_0.npy'\n","\n","with zipfile.ZipFile(time_zip_path) as z:\n","    # Handle any prefix path\n","    matching_file = next((f for f in z.namelist() if f.endswith(csv_file_name)), None)\n","\n","    if matching_file:\n","        with z.open(matching_file) as f:\n","            df = np.load(f)\n","            print(f\"\\nContents of {matching_file}:\")\n","            print(df)  # Show first 10 rows\n","    else:\n","        print(f\"File {csv_file_name} not found in ZIP.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ByyddmDlwdA","executionInfo":{"status":"ok","timestamp":1747273747621,"user_tz":-480,"elapsed":154,"user":{"displayName":"Shem Lawalata","userId":"13541090692546704517"}},"outputId":"5c24389d-ddf0-4b75-fd6a-034b6742e5ef"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["File 193264_0.npy not found in ZIP.\n"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y7rHn1lJm6bc","executionInfo":{"status":"ok","timestamp":1747273633361,"user_tz":-480,"elapsed":8,"user":{"displayName":"Shem Lawalata","userId":"13541090692546704517"}},"outputId":"6c582d06-720a-45bf-af85-a25a8a75e14f"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":[],"metadata":{"id":"ALPYXsE9n82F"},"execution_count":null,"outputs":[]}]}